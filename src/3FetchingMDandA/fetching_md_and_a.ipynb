{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ccdfc0",
   "metadata": {},
   "source": [
    "\n",
    "# 4.3.3 htmファイルからMD＆A情報としてみなされる文章のみを抽出 \n",
    "\n",
    "　htmファイルから、 BeautifulSoupを用いて MD＆A情報としてみなされる文章のみを抽出した。BeautifulSoupとは、Pythonのライブラリのひとつで、htmlやxmlといったWebページで用いられるデータを構文解析する際に用いられるライブラリである。今回は、 htm形式のテキストファイルからMD&A部分を抜き出し、htm形式のタグの除去等の処理を行って生の文章を抽出した。また文章を抽出においては、加藤・五島(2020)を参考に「１【経営方針、経営環境及び対処すべき課題等】」と「３【経営者による財政状態、経営成績及びキャッシュ・フローの状況の分析】」の 2 つの章のテキストをMD&Aの記述とみなして抽出を行った。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f83123e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "def fetch_md_and_a(data_frame_name, data_frame):\n",
    "\n",
    "    htm_files = call_htm_files(data_frame_name)\n",
    "    industry_htm_files_hash = make_industry_htm_files_hash(htm_files , data_frame_name, data_frame)\n",
    "    \n",
    "    sum_csv_output = 1\n",
    "    for industry_name, htm_files in industry_htm_files_hash.items():\n",
    "        \n",
    "        edinet_id_files_hash = {}\n",
    "        #Edninetの識別子ごとでファイル群を管理する\n",
    "        for file in htm_files:\n",
    "            pattern = 'E.*?-'\n",
    "            result = re.search(pattern, file)\n",
    "            start, end = result.span()\n",
    "            identifier = file[start: end-1]\n",
    "\n",
    "            if identifier in edinet_id_files_hash :\n",
    "                edinet_id_files_hash[identifier].append(file)\n",
    "            else:\n",
    "                edinet_id_files_hash[identifier] = [file]\n",
    "        \n",
    "        idx_num = 1\n",
    "        # すでにEdninetの識別子順でソートされている\n",
    "        for identifier, e_files in edinet_id_files_hash.items() :\n",
    "            # 「１【経営方針、経営環境及び対処すべき課題等】」,「３【経営者による財政状態、経営成績及びキャッシュ・フローの状況の分析】」            \n",
    "            #コロナ前, コロナ過渡期, コロナ後の最低３つがなかった時\n",
    "            if len(e_files) < 3:\n",
    "                print(f\"detected: {e_files}\")\n",
    "                continue\n",
    "            \n",
    "            date_files_hash = {}\n",
    "            for e_f in e_files:\n",
    "                date_str = get_date_str_val(e_f)\n",
    "                if date_str in date_files_hash :\n",
    "                    date_files_hash[date_str].append(e_f)\n",
    "                else:\n",
    "                    date_files_hash[date_str] = [e_f]\n",
    "            \n",
    "            for date_str, d_files in date_files_hash.items():\n",
    "                \n",
    "                d_files_len = len(d_files)\n",
    "\n",
    "                if d_files_len > 1:\n",
    "                    print(f\"count: {d_files_len}, {d_files}\")\n",
    "                \n",
    "                md_a_df = pd.DataFrame()\n",
    "                idx = 0\n",
    "                while  idx < d_files_len :\n",
    "                    sp = read_file(d_files[idx])\n",
    "                    htm_contents = sp.find('body').div.contents\n",
    "                    md_a_contents, func =  extract_md_a_contents(htm_contents)\n",
    "                    tmp_df = func(md_a_contents)                \n",
    "                    md_a_df  = pd.concat([md_a_df, tmp_df], axis=0)\n",
    "                    idx += 1\n",
    "\n",
    "                save_md_a_df_to_csv(md_a_df, idx_num, date_str , data_frame_name,  industry_name)\n",
    "                #beforeとafterでユニークなindex_numを持つようにする\n",
    "                idx_num += 1\n",
    "                \n",
    "                print(sum_csv_output, len(md_a_df))\n",
    "                sum_csv_output += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18f2d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_htm_files(data_frame_name):\n",
    "    htm_files = glob.glob(f\"/home/jovyan/2UnzippingHtm/UnzipedHtmFiles/{data_frame_name}/**/*.htm\", recursive=True)\n",
    "    return  htm_files\n",
    "\n",
    "\n",
    "def make_industry_htm_files_hash(htm_files , data_frame_name: str, data_frame):\n",
    "    industry_htm_files_hash = {}\n",
    "    \n",
    "    industry_list = make_type_of_industry_list(data_frame)\n",
    "    for industry in industry_list:\n",
    "        industry_htm_files_hash[industry]= list(filter(lambda x:  industry in x , htm_files))\n",
    "    \n",
    "    return  industry_htm_files_hash \n",
    "\n",
    "\n",
    "def make_type_of_industry_list(data_frame : pd.DataFrame, industry_col=\"[業種（東証）]\"):\n",
    "    return list(set(data_frame[industry_col]))\n",
    "\n",
    "\n",
    "def get_date_str_val(htm_file) :\n",
    "    date_str = htm_file[-20:-10]\n",
    "    return  date_str\n",
    "\n",
    "\n",
    "def read_file(htm_path: str) -> BeautifulSoup:\n",
    "    with open(htm_path, mode=\"r\") as f:\n",
    "        htm = f.read()\n",
    "        sp = BeautifulSoup(htm, \"html.parser\")\n",
    "        return sp\n",
    "\n",
    "\"\"\"\n",
    "htmファイルには3つのパターンが存在しているため、その都度ハンドリングをする\n",
    "\n",
    "\n",
    "1. smt_textパターン: 属性値にsmt_textを持っているhtm\n",
    "2. textjustify_spanパターン: smt_textを持たず、spanにテキスト情報を記載しているhtm\n",
    "3. text_indent?\n",
    "\"\"\"\n",
    "#-----------------------------------------------------\n",
    "#md_aの章番号を指定\n",
    "#企業によって全角と半角かわかれる可能性があるためどちらも判定\n",
    "# 「１【経営方針、経営環境及び対処すべき課題等】」,「３【経営者による財政状態、経営成績及びキャッシュ・フローの状況の分析】」\n",
    "# after_2017 = ['１', '1','３', '3']\n",
    "\n",
    "def extract_md_a_contents(htm_contents: list, chapter_numbers=['１', '1','３', '3']) -> tuple:\n",
    "    \n",
    "    #MD＆A情報を持つ章を抽出\n",
    "    md_a_contents = []\n",
    "    \n",
    "    for content in htm_contents :\n",
    "        #bs4.element.Tag型ではないとfindメソッドでtypeエラーを起こすため判定\n",
    "        if not isinstance(content, bs4.element.Tag) :\n",
    "            continue\n",
    "        \n",
    "        found = content.find(class_=re.compile(\"smt_head\"))\n",
    "        #findしたけどデータがない(s4.element.Tag型ではない)がない場合.textプロパティを呼び出す際にtypeエラーを起こすため判定\n",
    "        if not  found:\n",
    "            found = content.find(\"h3\")\n",
    "            if not  found:\n",
    "                continue\n",
    "            else: \n",
    "                func = insert_df_by_span_p\n",
    "        else :\n",
    "            func = insert_df_by_smt\n",
    "    \n",
    "        title = found.text\n",
    "        #md_aの章番号を指定\n",
    "            # \"1【経営方針、経営環境及び対処すべき課題等】\",\n",
    "            # \"3【経営者による財政状態、経営成績及びキャッシュ・フローの状況の分析】\"\n",
    "        #企業によって全角と半角か別れる可能性があるためどちらも判定\n",
    "        if title[0] in  chapter_numbers :\n",
    "             md_a_contents.append(content)\n",
    "            \n",
    "    return md_a_contents, func\n",
    "\n",
    "#------------------------------------------\n",
    "def insert_df_by_span_p(md_a_contents: list) -> pd.DataFrame:\n",
    "    \n",
    "    md_a_df = pd.DataFrame()\n",
    "\n",
    "    text_values = []\n",
    "    for content in  md_a_contents : \n",
    "        \n",
    "        # テキスト情報を持つbs4.element.Tag型のみ取得\n",
    "        found_values = content.find_all(\"p\")\n",
    "         # テキストを取得\n",
    "      \n",
    "        for val in found_values:\n",
    "            if val.parent.name in [\"td\" , \"tr\"] or val.parent.parent.name in [\"td\" , \"tr\"]:\n",
    "                continue\n",
    "    \n",
    "            if val.span != None:\n",
    "                text = val.span.text\n",
    "                if len(text) > 1:\n",
    "                    text_values.append(text)\n",
    "            else :\n",
    "                text = val.text\n",
    "                if len(text) > 1:\n",
    "                    text_values.append(text)\n",
    "     \n",
    "        tmp_df = pd.DataFrame()\n",
    "        tmp_df['Text'] = text_values \n",
    "        #pandas.DataFrame型に入れる\n",
    "        md_a_df  = pd.concat([md_a_df ,  tmp_df], axis=0)\n",
    "        \n",
    "    return md_a_df\n",
    "\n",
    "#-----------------------------------------------------\n",
    "def insert_df_by_smt(md_a_contents: list) -> pd.DataFrame:\n",
    "    \n",
    "    md_a_df = pd.DataFrame()\n",
    "\n",
    "    for content in  md_a_contents : \n",
    "        # テキスト情報を持つbs4.element.Tag型のみ取得\n",
    "        found_values = content.find_all(class_=re.compile(\"smt_text\"))\n",
    "         # テキストを取得\n",
    "        text_values = list(filter(lambda val: len(val) > 1, list(map(lambda val: val.text,found_values))))\n",
    "        tmp_df = pd.DataFrame()\n",
    "        tmp_df['Text'] = text_values \n",
    "        #pandas.DataFrame型に入れる\n",
    "        md_a_df  = pd.concat([md_a_df ,  tmp_df], axis=0)\n",
    "        \n",
    "    return md_a_df\n",
    "\n",
    "#----------------------------------------------\n",
    "        \n",
    "def save_md_a_df_to_csv(md_a_df: pd.DataFrame, idx_num: int, date_str: str,  data_frame_name, industry_name) -> None :\n",
    "    #Sampleフォルダの作成\n",
    "    \n",
    "    \n",
    "    filepath = os.getcwd()+ f\"/{data_frame_name}\"\n",
    "    if not os.path.exists(filepath) :\n",
    "        os.mkdir(filepath)\n",
    "        \n",
    "    filepath = os.getcwd()+ f\"/{data_frame_name}/{industry_name}\"\n",
    "    if not os.path.exists(filepath) :\n",
    "        os.mkdir(filepath)\n",
    "    \n",
    "    filepath_before_pandemic  = os.getcwd()+ f\"/{data_frame_name}/{industry_name}\"  +  \"/BeforeSample\"\n",
    "    if not os.path.exists(filepath_before_pandemic) :\n",
    "        os.mkdir(filepath_before_pandemic)\n",
    "    \n",
    "    filepath_transition_period_pandemic = os.getcwd()+ f\"/{data_frame_name}/{industry_name}\"  +  \"/TransitionPeriodSample\"\n",
    "    if not os.path.exists(filepath_transition_period_pandemic) :\n",
    "        os.mkdir(filepath_transition_period_pandemic)\n",
    "    \n",
    "    filepath_after_pandemic = os.getcwd()+ f\"/{data_frame_name}/{industry_name}\"  +  \"/AfterSample\"\n",
    "    if not os.path.exists(filepath_after_pandemic) :\n",
    "        os.mkdir(filepath_after_pandemic)\n",
    "            \n",
    "    \n",
    "    date_dt = dt.strptime(date_str, '%Y-%m-%d')\n",
    "    \n",
    "    before_pandemic_boundary_val = dt(2019, 3, 31)\n",
    "    \n",
    "    transition_period_pandemic_boundary_val = dt(2020, 3, 31)\n",
    "    if  date_dt <= before_pandemic_boundary_val :\n",
    "        md_a_df.to_csv(filepath_before_pandemic+\"/\"+f'{idx_num}_{date_str}.csv')\n",
    "    elif  date_dt <= transition_period_pandemic_boundary_val :\n",
    "        md_a_df.to_csv(filepath_transition_period_pandemic +\"/\"+f'{idx_num}_{date_str}.csv')\n",
    "    else :\n",
    "        md_a_df.to_csv(filepath_after_pandemic+\"/\"+f'{idx_num}_{date_str}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42713a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_frame_name =\"hirenketsu\" \n",
    "data_frame = pd.read_csv(\"/home/jovyan/1CalliingEdinetApi\"+f\"/EdinetIdxFiles/edinet_{data_frame_name}.csv\", skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ecb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 126\n",
      "2 127\n",
      "3 129\n",
      "4 34\n",
      "5 34\n",
      "6 42\n",
      "7 59\n",
      "8 25\n",
      "9 30\n",
      "10 140\n",
      "11 137\n",
      "12 161\n",
      "13 58\n",
      "14 59\n",
      "15 62\n",
      "16 46\n",
      "17 50\n",
      "18 88\n",
      "19 44\n",
      "20 47\n",
      "21 62\n",
      "22 101\n",
      "23 104\n",
      "24 58\n",
      "25 41\n",
      "26 37\n",
      "27 78\n",
      "28 48\n",
      "29 46\n",
      "30 50\n",
      "31 128\n",
      "32 127\n",
      "33 181\n",
      "34 118\n",
      "35 118\n",
      "36 120\n",
      "37 120\n",
      "38 114\n",
      "39 152\n",
      "40 148\n",
      "41 156\n",
      "42 156\n",
      "43 114\n",
      "44 111\n",
      "45 119\n",
      "46 97\n",
      "47 83\n",
      "48 86\n",
      "49 65\n",
      "50 67\n",
      "51 61\n",
      "52 58\n",
      "53 57\n",
      "54 66\n",
      "55 94\n",
      "56 109\n",
      "57 119\n",
      "58 73\n",
      "59 78\n",
      "60 87\n",
      "61 101\n",
      "62 105\n",
      "63 106\n",
      "64 106\n",
      "65 104\n",
      "66 137\n",
      "67 62\n",
      "68 51\n",
      "69 73\n",
      "70 33\n",
      "71 39\n",
      "72 44\n",
      "73 27\n",
      "74 27\n",
      "75 30\n",
      "76 98\n",
      "77 99\n",
      "78 116\n",
      "79 90\n",
      "80 90\n",
      "81 101\n",
      "82 150\n",
      "83 143\n",
      "84 122\n",
      "85 26\n",
      "86 38\n",
      "87 36\n",
      "88 92\n",
      "89 104\n",
      "90 109\n",
      "91 39\n",
      "92 53\n",
      "93 56\n",
      "94 59\n",
      "95 81\n",
      "96 94\n",
      "97 70\n",
      "98 70\n",
      "99 77\n",
      "100 113\n",
      "101 124\n",
      "102 121\n",
      "103 148\n",
      "104 148\n",
      "105 140\n",
      "106 101\n",
      "107 110\n",
      "108 105\n",
      "109 52\n",
      "110 52\n",
      "111 78\n",
      "112 138\n",
      "113 138\n",
      "114 137\n",
      "115 213\n",
      "116 187\n",
      "117 198\n",
      "118 184\n",
      "119 183\n",
      "120 160\n",
      "121 78\n",
      "122 107\n",
      "123 59\n",
      "124 61\n",
      "125 69\n",
      "126 75\n",
      "127 119\n",
      "128 122\n",
      "129 97\n",
      "130 70\n",
      "131 84\n",
      "132 94\n",
      "133 74\n",
      "134 83\n",
      "135 100\n",
      "136 149\n",
      "137 138\n",
      "138 220\n",
      "139 80\n",
      "140 84\n",
      "141 74\n",
      "142 47\n",
      "143 51\n",
      "144 62\n",
      "145 49\n",
      "146 49\n",
      "147 68\n",
      "148 72\n",
      "149 63\n",
      "150 94\n",
      "151 46\n",
      "152 49\n",
      "153 63\n",
      "154 86\n",
      "155 94\n",
      "156 101\n",
      "157 51\n",
      "158 55\n",
      "159 73\n",
      "160 85\n",
      "161 87\n",
      "162 89\n",
      "163 50\n",
      "164 59\n",
      "165 59\n",
      "166 65\n",
      "167 72\n",
      "168 39\n",
      "169 152\n",
      "170 157\n",
      "171 139\n",
      "172 81\n",
      "173 80\n",
      "174 79\n",
      "175 10\n",
      "176 28\n",
      "177 39\n",
      "178 172\n",
      "179 111\n",
      "180 86\n",
      "181 90\n",
      "182 107\n",
      "183 118\n",
      "184 112\n",
      "185 112\n",
      "186 115\n",
      "187 70\n",
      "188 139\n",
      "189 165\n",
      "190 54\n",
      "191 102\n",
      "192 114\n",
      "193 101\n",
      "194 113\n",
      "195 123\n",
      "196 199\n",
      "197 198\n",
      "198 73\n",
      "199 223\n",
      "200 256\n",
      "201 276\n",
      "202 36\n",
      "203 36\n",
      "204 50\n",
      "205 57\n",
      "206 57\n",
      "207 67\n",
      "208 140\n",
      "209 149\n",
      "210 153\n",
      "211 58\n",
      "212 60\n",
      "213 119\n",
      "214 90\n",
      "215 87\n",
      "216 90\n",
      "217 73\n",
      "218 78\n",
      "219 76\n",
      "220 107\n",
      "221 114\n",
      "222 127\n",
      "223 76\n",
      "224 77\n",
      "225 55\n",
      "226 27\n",
      "227 28\n",
      "228 36\n",
      "229 93\n",
      "230 89\n",
      "231 92\n",
      "232 528\n",
      "233 500\n",
      "234 167\n",
      "235 66\n",
      "236 68\n",
      "237 120\n",
      "238 150\n",
      "239 141\n",
      "240 194\n",
      "241 120\n",
      "242 97\n",
      "243 79\n",
      "244 82\n",
      "245 87\n",
      "246 70\n",
      "247 201\n",
      "248 213\n",
      "249 190\n",
      "250 121\n",
      "251 122\n",
      "252 141\n",
      "253 131\n",
      "254 182\n",
      "255 179\n",
      "256 123\n",
      "257 126\n",
      "258 148\n",
      "259 59\n",
      "260 55\n",
      "261 62\n",
      "262 54\n",
      "263 43\n",
      "264 56\n",
      "265 52\n",
      "266 56\n",
      "267 65\n",
      "268 119\n",
      "269 119\n",
      "270 118\n",
      "271 60\n",
      "272 65\n",
      "273 80\n",
      "274 62\n",
      "275 22\n",
      "276 42\n",
      "277 83\n",
      "278 85\n",
      "279 98\n",
      "280 96\n",
      "281 97\n",
      "282 127\n",
      "283 89\n",
      "284 88\n",
      "285 106\n",
      "286 10\n",
      "287 16\n",
      "288 26\n",
      "289 32\n",
      "290 27\n",
      "291 26\n",
      "292 42\n",
      "293 65\n",
      "294 63\n",
      "295 64\n",
      "296 63\n",
      "297 48\n",
      "298 21\n",
      "299 41\n",
      "300 65\n",
      "301 96\n",
      "302 119\n",
      "303 109\n",
      "304 164\n",
      "305 148\n",
      "306 114\n",
      "307 89\n",
      "308 97\n",
      "309 122\n",
      "310 57\n",
      "311 89\n",
      "312 118\n",
      "313 115\n",
      "314 120\n",
      "315 128\n",
      "316 108\n",
      "317 101\n",
      "318 95\n",
      "319 111\n",
      "320 120\n",
      "321 138\n",
      "322 69\n",
      "323 69\n",
      "324 67\n",
      "325 60\n",
      "326 70\n",
      "327 73\n",
      "328 138\n",
      "329 163\n",
      "330 195\n",
      "331 123\n",
      "332 114\n",
      "333 116\n",
      "334 60\n",
      "335 60\n",
      "336 73\n",
      "337 58\n",
      "338 53\n",
      "339 50\n",
      "340 111\n",
      "341 112\n",
      "342 125\n",
      "343 161\n",
      "344 117\n",
      "345 145\n",
      "346 87\n",
      "347 89\n",
      "348 96\n",
      "349 67\n",
      "350 67\n",
      "351 83\n",
      "352 100\n",
      "353 101\n",
      "354 112\n",
      "355 119\n",
      "356 122\n",
      "357 124\n",
      "358 79\n",
      "359 85\n",
      "360 85\n",
      "361 74\n",
      "362 49\n",
      "363 129\n",
      "364 127\n",
      "365 127\n",
      "366 137\n",
      "367 72\n",
      "368 76\n",
      "369 182\n",
      "370 75\n",
      "371 76\n",
      "372 80\n",
      "373 125\n",
      "374 125\n",
      "375 132\n",
      "376 75\n",
      "377 83\n",
      "378 76\n",
      "379 161\n",
      "380 155\n",
      "381 167\n",
      "382 177\n",
      "383 175\n",
      "384 163\n",
      "385 112\n",
      "386 124\n",
      "387 143\n",
      "388 89\n",
      "389 122\n",
      "390 143\n",
      "391 188\n",
      "392 181\n",
      "393 176\n",
      "394 117\n",
      "395 117\n",
      "396 118\n",
      "397 117\n",
      "398 109\n",
      "399 112\n",
      "400 70\n",
      "401 71\n",
      "402 91\n",
      "403 143\n",
      "404 146\n",
      "405 123\n",
      "406 116\n",
      "407 114\n",
      "408 120\n",
      "409 122\n",
      "410 125\n",
      "411 139\n",
      "412 165\n",
      "413 195\n",
      "414 210\n",
      "415 164\n",
      "416 184\n",
      "417 159\n",
      "418 24\n",
      "419 37\n",
      "420 40\n",
      "421 66\n",
      "422 64\n",
      "423 70\n",
      "424 70\n",
      "425 73\n",
      "426 71\n",
      "427 72\n",
      "428 71\n",
      "429 84\n",
      "430 152\n",
      "431 156\n",
      "432 231\n",
      "433 58\n",
      "434 59\n",
      "435 68\n",
      "436 169\n",
      "437 169\n",
      "438 216\n",
      "439 122\n",
      "440 132\n",
      "441 143\n",
      "442 143\n",
      "443 128\n",
      "444 137\n",
      "445 186\n",
      "446 180\n",
      "447 216\n",
      "448 162\n",
      "449 161\n",
      "450 164\n",
      "451 146\n",
      "452 132\n",
      "453 147\n",
      "454 117\n",
      "455 129\n",
      "456 127\n",
      "457 142\n",
      "458 138\n",
      "459 155\n",
      "460 188\n",
      "461 147\n",
      "462 131\n",
      "463 158\n",
      "464 164\n",
      "465 174\n",
      "466 109\n",
      "467 109\n",
      "468 127\n",
      "469 78\n",
      "470 72\n",
      "471 78\n",
      "472 31\n",
      "473 32\n",
      "474 38\n",
      "475 72\n",
      "476 73\n",
      "477 81\n",
      "478 141\n",
      "479 125\n",
      "480 123\n",
      "481 239\n",
      "482 236\n",
      "483 277\n",
      "484 48\n",
      "485 47\n",
      "486 56\n",
      "487 258\n",
      "488 263\n",
      "489 143\n",
      "490 77\n",
      "491 76\n",
      "492 102\n",
      "493 71\n",
      "494 72\n",
      "495 76\n",
      "496 27\n",
      "497 28\n",
      "498 37\n",
      "499 97\n",
      "500 104\n",
      "501 109\n",
      "502 54\n",
      "503 56\n",
      "504 111\n",
      "505 76\n",
      "506 84\n"
     ]
    }
   ],
   "source": [
    "fetch_md_and_a(data_frame_name, data_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
